
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>segment.cl &#8212; Streamlines  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="label.cl" href="label.cl.html" />
    <link rel="prev" title="countlink.cl" href="countlink.cl.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="segment-cl">
<h1><code class="docutils literal notranslate"><span class="pre">segment.cl</span></code><a class="headerlink" href="#segment-cl" title="Permalink to this headline">Â¶</a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>///
/// @file segment.cl
///
/// Kernels to (sub)segment landscape into smallish patches from channels to ridges
///
/// @author CPS
/// @bug No known bugs
///

///
/// @defgroup segmentation Channel and hillslope segmentation
/// Segment and subsegment hillslopes and adjacent channels into smallish zones
///

#ifdef KERNEL_SEGMENT_DOWNCHANNELS
///
/// TBD
///
/// Compiled if KERNEL_SEGMENT_DOWNCHANNELS is defined.
///
/// @param[in]     seed_point_array: list of initial streamline point vectors,
///                                  one allotted to each kernel instance
/// @param[in]     mask_array: grid pixel mask (padded),
///                            with @p true = masked, @p false = good
/// @param[in]     uv_array: flow unit velocity vector grid (padded)
/// @param[in]     mapping_array: flag grid recording status of each pixel (padded)
/// @param[in]     count_array: counter grid recording number of pixel steps
///                             downstream from dominant channel head (padded)
/// @param[in]     link_array: link grid providing the grid array index of the next
///                             downstream pixel (padded)
/// @param[in,out] label_array: label grid giving the ID of the subsegment to which
///                             this pixel belongs (padded); the MSB is set if left flank
///
/// @returns void
///
/// @ingroup kernels segmentation
///
__kernel void segment_downchannels(
        __global const float2 *seed_point_array,
        __global const bool   *mask_array,
        __global const float2 *uv_array,
        __global const uint   *mapping_array,
        __global const uint   *count_array,
        __global const uint   *link_array,
        __global       uint   *label_array
   )
{
    // For every channel head pixel...

    const uint global_id = get_global_id(0u)+get_global_id(1u)*get_global_size(0u);
    __private uint idx, prev_idx, segment_label=0u,
                   segmentation_counter=SEGMENTATION_THRESHOLD;
    __private float2 vec = seed_point_array[global_id];

    // Remember here
    prev_idx = get_array_idx(vec);
    // Label this stream segment, starting with the head pixel
    segment_label = prev_idx;
    atomic_xchg(&amp;label_array[prev_idx],segment_label);
    // Step downstream
    idx = link_array[prev_idx];
    // Continue stepping downstream until a dominant confluence
    //    or a masked pixel is reached
    while (!mask_array[idx] &amp;&amp; prev_idx!=idx) {
        if ((mapping_array[idx]) &amp; IS_MAJORCONFLUENCE) {
            if ((mapping_array[prev_idx]) &amp; IS_MAJORINFLOW) {
                if (count_array[idx]&gt;=segmentation_counter) {
                    segment_label = idx;
                    segmentation_counter += SEGMENTATION_THRESHOLD;
                }
            } else {
                break;
            }
        }
        // Label here with the current segment&#39;s label
        atomic_xchg(&amp;label_array[idx],segment_label);
        // Continue downstream
        prev_idx = idx;
        idx = link_array[idx];
    }
    return;
}
#endif

#ifdef KERNEL_SEGMENT_HILLSLOPES
///
/// TBD
///
/// Compiled if KERNEL_SEGMENT_HILLSLOPES is defined.
///
/// @param[in]     seed_point_array: list of initial streamline point vectors,
///                                  one allotted to each kernel instance
/// @param[in]     mask_array: grid pixel mask (padded),
///                            with @p true = masked, @p false = good
/// @param[in]     uv_array: flow unit velocity vector grid (padded)
/// @param[in]     mapping_array: flag grid recording status of each pixel (padded)
/// @param[in]     count_array: counter grid recording number of pixel steps
///                             downstream from dominant channel head (padded)
/// @param[in]     link_array: link grid providing the grid array index of the next
///                             downstream pixel (padded)
/// @param[in,out] label_array: label grid giving the ID of the subsegment to which
///                             this pixel belongs (padded); the MSB is set if left flank
///
/// @returns void
///
/// @ingroup kernels segmentation
///
__kernel void segment_hillslopes(
        __global const float2 *seed_point_array,
        __global const bool   *mask_array,
        __global const float2 *uv_array,
        __global const uint   *mapping_array,
        __global const uint   *count_array,
        __global const uint   *link_array,
        __global       uint   *label_array
   )
{
    // For every non-thin-channel pixel

    const uint global_id = get_global_id(0u)+get_global_id(1u)*get_global_size(0u);
    __private uint idx, hillslope_idx, n_steps=0u;
    __private float dl=0.0f, dt=DT_MAX;
    __private float2 uv1_vec, uv2_vec, dxy1_vec, dxy2_vec,
                     vec = seed_point_array[global_id], next_vec;

    // Remember here
    idx = get_array_idx(vec);
    hillslope_idx = idx;
    // Integrate downstream until a channel pixel (or masked pixel) is reached
    while (!mask_array[idx] &amp;&amp; ((~mapping_array[idx])&amp;IS_THINCHANNEL)
           &amp;&amp; n_steps&lt;(MAX_N_STEPS-1)) {
        compute_step_vec(dt, uv_array, &amp;dxy1_vec, &amp;dxy2_vec, &amp;uv1_vec, &amp;uv2_vec,
                         vec, &amp;next_vec, &amp;idx);
        if (segment_runge_kutta_step(&amp;dt, &amp;dl, &amp;dxy1_vec, &amp;dxy2_vec,
                                     &amp;vec, &amp;next_vec, &amp;n_steps, &amp;idx))
            break;
    }
    if (mapping_array[idx]&amp;IS_THINCHANNEL) {
        // We&#39;ve reached a (thin) channel, so grab its label and apply it to
        //   the source hillslope pixel
        atomic_xchg(&amp;label_array[hillslope_idx],label_array[idx]);
    }
    return;
}
#endif

#ifdef KERNEL_SUBSEGMENT_CHANNEL_EDGES
///
/// TBD
///
/// Compiled if KERNEL_SUBSEGMENT_CHANNEL_EDGES is defined.
///
/// @param[in]     seed_point_array: list of initial streamline point vectors,
///                                  one allotted to each kernel instance
/// @param[in]     mask_array: grid pixel mask (padded),
///                            with @p true = masked, @p false = good
/// @param[in]     uv_array: flow unit velocity vector grid (padded)
/// @param[in,out] mapping_array: flag grid recording status of each pixel (padded)
/// @param[in]     channel_label_array: copy of the label grid array
/// @param[in]     link_array: link grid providing the grid array index of the next
///                            downstream pixel (padded)
/// @param[in,out] label_array: label grid giving the ID of the subsegment to which
///                             this pixel belongs (padded); the MSB is set if left flank
///
/// @returns void
///
/// @ingroup kernels segmentation
///
__kernel void subsegment_channel_edges(
        __global const float2 *seed_point_array,
        __global const bool   *mask_array,
        __global const float2 *uv_array,
        __global       uint   *mapping_array,
        __global const uint   *channel_label_array,
        __global const uint   *link_array,
        __global       uint   *label_array
   )
{
    // For every channel head and major confluence pixel...

    const uint global_id = get_global_id(0u)+get_global_id(1u)*get_global_size(0u);
    __private uint idx, prev_idx, left_idx, segment_label=0u, prev_x,prev_y, x,y, n_turns;
    __private char dx,dy, rotated_dx,rotated_dy;
    __private float2 vec = seed_point_array[global_id];

    // Remember here
    prev_idx = get_array_idx(vec);
    segment_label = channel_label_array[prev_idx];
    // Step downstream off channel head / major confluence pixel
    idx = link_array[prev_idx];
    // Even if this pixel is masked, we still need to try to subsegment
    while (prev_idx!=idx) {

#ifdef F_ORDER
        prev_x = prev_idx%NX_PADDED;
        prev_y = prev_idx/NX_PADDED;
        x =  idx%NX_PADDED;
        y =  idx/NX_PADDED;
#else
        prev_x = prev_idx/NY_PADDED;
        prev_y = prev_idx%NY_PADDED;
        x =  idx/NY_PADDED;
        y =  idx%NY_PADDED;
#endif
        dx = (char)(x-prev_x);
        dy = (char)(y-prev_y);

        // Rotate 45deg anticlockwise repeatedly until a non-fillable pixel is reached
        n_turns = 0;
        while (left_idx!=prev_idx &amp;&amp; ++n_turns&lt;=4) {
            rotated_dx = dx-dy;
            rotated_dy = dx+dy;
            rotated_dx = rotated_dx/clamp((char)abs(rotated_dx),(char)1,(char)2);
            rotated_dy = rotated_dy/clamp((char)abs(rotated_dy),(char)1,(char)2);
            dx = rotated_dx;
            dy = rotated_dy;
#ifdef F_ORDER
            left_idx = (prev_x+rotated_dx) + (prev_y+rotated_dy)*NX_PADDED;
#else
            left_idx = (prev_x+rotated_dx)*NY_PADDED + (prev_y+rotated_dy);
#endif
            if (!mask_array[left_idx] &amp;&amp; label_array[left_idx]==segment_label) {
                if ((mapping_array[left_idx]) &amp; IS_THINCHANNEL) {
                    if (n_turns&gt;1) {
                        break;
                    }
                } else {
                    atomic_or(&amp;mapping_array[left_idx],IS_LEFTFLANK);
                    atomic_or(&amp;label_array[left_idx],LEFT_FLANK_ADDITION);
                }
            }
        }

        // Step further downstream if necessary
        prev_idx = idx;
        idx = link_array[idx];
        // Stop if we&#39;ve reached the next major confluence pixel, or the mask
        if (!mask_array[idx] &amp;&amp; (   ((mapping_array[prev_idx]) &amp; IS_MAJORCONFLUENCE)
                                 || ((mapping_array[prev_idx]) &amp; IS_MAJORINFLOW)
                                 || ((mapping_array[prev_idx]) &amp; IS_MINORINFLOW)
                                 ) ) {
            break;
        }
    }
    return;
}
#endif

#ifdef KERNEL_SUBSEGMENT_FLANKS
///
/// TBD
///
/// Compiled if KERNEL_SUBSEGMENT_FLANKS is defined.
///
/// @param[in]  seed_point_array: list of initial streamline point vectors,
///                               one allotted to each kernel instance
/// @param[in]  mask_array: grid pixel mask (padded),
///                         with @p true = masked, @p false = good
/// @param[in]  uv_array: flow unit velocity vector grid (padded)
/// @param[in,out] mapping_array: flag grid recording status of each pixel (padded)
/// @param[in,out] count_array: counter grid recording number of pixel steps
///                             downstream from dominant channel head (padded)
/// @param[in,out] link_array: link grid providing the grid array index of the next
///                             downstream pixel (padded)
/// @param[in,out] label_array: label grid giving the ID of the subsegment to which
///                             this pixel belongs (padded); the MSB is set if left flank
///
/// @returns void
///
/// @ingroup kernels segmentation
///
__kernel void subsegment_flanks(
        __global const float2 *seed_point_array,
        __global const bool   *mask_array,
        __global const float2 *uv_array,
        __global const uint   *mapping_array,
        __global const uint   *count_array,
        __global const uint   *link_array,
        __global       uint   *label_array
   )
{
    // For every non-left-flank hillslope pixel...

    const uint global_id = get_global_id(0u)+get_global_id(1u)*get_global_size(0u);
    __private uint idx, hillslope_idx, n_steps=0u;
    __private float dl=0.0f, dt=DT_MAX;
    __private float2 uv1_vec, uv2_vec, dxy1_vec, dxy2_vec,
                     vec = seed_point_array[global_id], next_vec;

    // Remember here
    idx = get_array_idx(vec);
    hillslope_idx = idx;
    // Integrate downstream until thin channel or left-flank pixel is reached
    while (!mask_array[idx] &amp;&amp; ((~mapping_array[idx])&amp;IS_LEFTFLANK)
            &amp;&amp; ((~mapping_array[idx])&amp;IS_THINCHANNEL) &amp;&amp; n_steps&lt;(MAX_N_STEPS-1)) {
        compute_step_vec(dt, uv_array, &amp;dxy1_vec, &amp;dxy2_vec, &amp;uv1_vec, &amp;uv2_vec,
                         vec, &amp;next_vec, &amp;idx);
        if (segment_runge_kutta_step(&amp;dt, &amp;dl, &amp;dxy1_vec, &amp;dxy2_vec,
                                     &amp;vec, &amp;next_vec, &amp;n_steps, &amp;idx))
            break;
    }
    if (mapping_array[idx]&amp;IS_LEFTFLANK) {
        // We&#39;ve reached a (thin) channel, so grab its label and apply it to
        //   the source hillslope pixel
        // No need for atomic here since we&#39;re writing to the source pixel
        label_array[hillslope_idx] |= LEFT_FLANK_ADDITION;
//        atomic_or(&amp;label_array[hillslope_idx],LEFT_FLANK_ADDITION);
    }
    return;
}
#endif
</pre></div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/../_images/icon2.png" alt="Logo"/>
    
    <h1 class="logo logo-name">Streamlines</h1>
    
  </a>
</p>



<p class="blurb">Topographic streamline mapping of landscape structure</p>







<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script><div class="relations">
<h3>Related</h3>
<ul>
  <li><a href="../index.html"></a><ul>
      <li><a href="countlink.cl.html" title="previous chapter"><code class="docutils literal notranslate"><span class="pre">countlink.cl</span></code></a></li>
      <li><a href="label.cl.html" title="next chapter"><code class="docutils literal notranslate"><span class="pre">label.cl</span></code></a></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, CPS.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/modules/segment.cl.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>